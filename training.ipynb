        "def feature_mda_cv(X_tr: pd.DataFrame,",
        "",
        "                   folds: list,",
        "",
        "                   fold_models: list,",
        "",
        "                   features: list | None = None,",
        "",
        "                   n_perm: int = 20,",
        "",
        "                   random_state: int = 42,",
        "",
        "                   verbose: bool = True):",
        "",
        "    \"\"\"",
        "",
        "    Para cada feature j:",
        "",
        "      ΔAP_fold(j) = mean_perm( AP_base - AP_perm ) en cada fold.",
        "",
        "    Luego agregamos entre folds: mediana, q25, mean, std, hit-rate.",
        "",
        "    Usa los mismos sample_weight de validación guardados en fold_models (unicidad).",
        "",
        "    \"\"\"",
        "",
        "    rng = np.random.default_rng(random_state)",
        "",
        "    feats = list(features) if features is not None else list(X_tr.columns)",
        "",
        "    per_fold = {j: [] for j in feats}",
        "",
        "",
        "",
        "    # Recorremos folds",
        "",
        "    for f, fm in zip(folds, fold_models):",
        "",
        "        if fm is None or not np.isfinite(fm.get(\"ap_base\", np.nan)):",
        "",
        "            continue",
        "",
        "        k = fm[\"k\"]",
        "",
        "        model = fm[\"model\"]",
        "",
        "        va_rows = fm[\"val_rows\"]",
        "",
        "        y_val = fm[\"y_val\"]",
        "",
        "        ap_base = fm[\"ap_base\"]",
        "",
        "        w_val = fm.get(\"w_val\", None)",
        "",
        "        Xv_base = X_tr.iloc[va_rows].copy()",
        "",
        "",
        "",
        "        # Loop por feature",
        "",
        "        for j in feats:",
        "",
        "            if j not in Xv_base.columns:",
        "",
        "                per_fold[j].append(np.nan)",
        "",
        "                continue",
        "",
        "            deltas = []",
        "",
        "            for _ in range(n_perm):",
        "",
        "                perm_idx = rng.permutation(len(Xv_base))",
        "",
        "                Xv = Xv_base.copy()",
        "",
        "                Xv.loc[:, j] = Xv_base.iloc[perm_idx][j].values",
        "",
        "                proba_perm = model.predict_proba(Xv)[:,1]",
        "",
        "                ap_perm = _ap_safe(y_val, proba_perm, sample_weight=w_val)",
        "",
        "                if np.isfinite(ap_perm):",
        "",
        "                    deltas.append(ap_base - ap_perm)",
        "",
        "            per_fold[j].append(float(np.mean(deltas)) if deltas else np.nan)",
        "",
        "",
        "",
        "        if verbose:",
        "",
        "            print(f\"[Fold {k}] procesado. n_features={len(feats)}\")",
        "",
        "",
        "",
        "    # Agregación entre folds",
        "",
        "    rows = []",
        "",
        "    K = sum(1 for fm in fold_models if fm is not None and np.isfinite(fm.get(\"ap_base\", np.nan)))",
        "",
        "    for j, vals in per_fold.items():",
        "",
        "        arr = np.array(vals, dtype=float)",
        "",
        "        k_supp = int(np.sum(np.isfinite(arr)))",
        "",
        "        med = float(np.nanmedian(arr)) if k_supp else np.nan",
        "",
        "        q25 = float(np.nanpercentile(arr,25)) if k_supp else np.nan",
        "",
        "        mean= float(np.nanmean(arr)) if k_supp else np.nan",
        "",
        "        std = float(np.nanstd(arr)) if k_supp else np.nan",
        "",
        "        hit = float(np.nanmean(arr>0)) if k_supp else np.nan  # % folds con ΔAP_fold>0",
        "",
        "        rows.append([j, med, q25, mean, std, hit, k_supp, vals])",
        "",
        "",
        "",
        "    res = pd.DataFrame(rows, columns=[",
        "",
        "        \"feature\",\"dAPF_median\",\"dAPF_q25\",\"dAPF_mean\",\"dAPF_std\",\"hit_rate\",\"k_support\",\"per_fold\"",
        "",
        "    ]).sort_values([\"dAPF_median\",\"dAPF_q25\",\"hit_rate\"], ascending=[False,False,False]).reset_index(drop=True)",
        "",
        "",
        "",
        "    print(f\"=== Feature MDA (n_perm={n_perm}) — agregado por fold ===\")",
        "",
        "    display(res.head(15))",
        "",
        "    return res, per_fold",
        "",
        "",
        "",
        "# ---------- HAC + deduplicación ----------",
        "",
        "",
        "",
        "from scipy.cluster.hierarchy import linkage, dendrogram",
        "",
        "from scipy.spatial.distance import squareform",
        "",
        "",
        "",
        "",
        "",
        "def plot_feature_dendrogram(X_tr: pd.DataFrame, features: list,",
        "",
        "                            corr_method: str = \"spearman\",",
        "",
        "                            use_abs: bool = True,",
        "",
        "                            linkage_method: str = \"average\",",
        "",
        "                            corr_cut: float = 0.90,",
        "",
        "                            max_leaves: int = 120,",
        "",
        "                            title: str = \"HAC (features shortlist)\"):",
        "",
        "    Xs = X_tr[features].dropna(axis=0, how=\"any\")",
        "",
        "    C = _spearman_corr(Xs) if corr_method==\"spearman\" else Xs.corr(method=corr_method)",
        "",
        "    D = _dist_hrp_from_corr(C, use_abs=use_abs)",
        "",
        "    Z = linkage(squareform(D.values, checks=False), method=linkage_method)",
        "",
        "    import matplotlib.pyplot as plt",
        "",
        "    plt.figure(figsize=(14,5))",
        "",
        "    dendrogram(Z, truncate_mode='lastp' if C.shape[1]>max_leaves else None,",
        "",
        "               p=max_leaves if C.shape[1]>max_leaves else 0,",
        "",
        "               leaf_rotation=90., leaf_font_size=8., show_contracted=True)",
        "",
        "    d_cut = float(np.sqrt(0.5*(1.0 - abs(corr_cut))))",
        "",
        "    plt.axhline(d_cut, color=\"#e74c3c\", ls=\"--\", lw=1.2, label=f\"d_cut={d_cut:.3f} (|ρ|={corr_cut})\")",
        "",
        "    plt.legend(loc=\"upper right\"); plt.title(title); plt.ylabel(\"distance\"); plt.grid(alpha=0.2)",
        "",
        "    plt.show()",
        "",
        "",
        "",
        "    return keep",
        "",
        "",
        "",
        "# ---------- Orquestador ----------",
        "",
        "def run_feature_mda_auto(X_tr: pd.DataFrame,",
        "",
        "                         y_tr: np.ndarray,",
        "",
        "                         ids_tr: list,",
        "",
        "                         folds: list,",
        "",
        "                         labels_df: pd.DataFrame,",
        "",
        "                         index_ref,   # e.g., data.index",
        "",
        "                         config: dict | None = None):",
        "",
        "    \"\"\"",
        "",
        "    Pipeline automático (hasta Etapa D):",
        "",
        "      - Unicidad por fold",
        "",
        "      - Baseline CV (RF) con unicidad",
        "",
        "      - MDA individual Stage-1 (rápido) en TODAS las features",
        "",
        "      - Shortlist por umbrales + topM",
        "",
        "      - MDA individual Stage-2 (fino) solo en shortlist",
        "",
        "      - HAC + deduplicación por |ρ| (opcional) + dendrograma (opcional)",
        "",
        "    Retorna: whitelist_final, report (dict con tablas intermedias)",
        "",
        "    \"\"\"",
        "",
        "    # Mezcla de config",
        "",
        "    CFG = DEFAULT_FEATURE_MDA_AUTO_CFG.copy()",
        "",
        "    if config:",
        "",
        "        for k,v in config.items():",
        "",
        "            if isinstance(v, dict) and k in CFG: CFG[k].update(v)",
        "",
        "            else: CFG[k] = v",
        "",
        "    verbose = CFG.get(\"verbose\", True)",
        "",
        "    rng_seed = CFG[\"random_state\"]",
        "",
        "",
        "",
        "    # Unicidad por fold",
        "",
        "    labels_idx = _build_event_intervals_guard(labels_df, index_ref)",
        "",
        "    if CFG[\"weights\"][\"use_uniqueness\"]:",
        "",
        "        w_train_by_fold = _uniqueness_by_fold(folds, labels_idx, len(index_ref), normalize=CFG[\"weights\"][\"normalize\"], kind=\"train\")",
        "",
        "        w_val_by_fold   = _uniqueness_by_fold(folds, labels_idx, len(index_ref), normalize=CFG[\"weights\"][\"normalize\"], kind=\"val\")",
        "",
        "    else:",
        "",
        "        w_train_by_fold = {f[\"k\"]: None for f in folds}",
        "",
        "        w_val_by_fold   = {f[\"k\"]: None for f in folds}",
        "",
        "",
        "",
        "    # Baseline por fold (usa tu función si ya estaba definida)",
        "",
        "    fold_models, ap_bases = train_baseline_models_cv(",
        "",
        "        X_tr, y_tr, ids_tr, folds,",
        "",
        "        w_train_by_fold=w_train_by_fold,",
        "",
        "        w_val_by_fold=w_val_by_fold,",
        "",
        "        rf_params=CFG[\"baseline\"][\"rf_params\"]",
        "",
        "    )",
        "",
        "",
        "",
        "    # Stage-1: MDA rápido en todas las features",
        "",
        "    res1, per_fold1 = feature_mda_cv(",
        "",
        "        X_tr=X_tr, folds=folds, fold_models=fold_models,",
        "",
        "        features=list(X_tr.columns),",
        "",
        "        n_perm=CFG[\"mda\"][\"stage1_n_perm\"],",
        "",
        "        random_state=rng_seed,",
        "",
        "        verbose=verbose",
        "",
        "    )",
        "",
        "",
        "",
        "    # Shortlist por umbrales + topM",
        "",
        "    thr_med = CFG[\"mda\"][\"median_gt\"]; thr_q25 = CFG[\"mda\"][\"q25_gt\"]; hr_min = CFG[\"mda\"][\"hit_rate_min\"]",
        "",
        "    mask_pass = (res1[\"dAPF_median\"] > thr_med) & (res1[\"dAPF_q25\"] > thr_q25) & (res1[\"hit_rate\"] >= hr_min)",
        "",
        "    shortlist_A = set(res1.loc[mask_pass, \"feature\"].tolist())",
        "",
        "    topM = int(CFG[\"mda\"][\"topM\"]) if CFG[\"mda\"][\"topM\"] else 250",
        "",
        "    shortlist_B = set(res1.sort_values([\"dAPF_median\",\"dAPF_q25\",\"hit_rate\"], ascending=False).head(topM)[\"feature\"].tolist())",
        "",
        "    shortlist = list(dict.fromkeys(list(shortlist_A | shortlist_B)))",
        "",
        "",
        "",
        "    if verbose:",
        "",
        "        print(f\"\\n[Stage-1] Pasa umbrales: {len(shortlist_A)} | TopM: {len(shortlist_B)} | Shortlist total: {len(shortlist)}\")",
        "",
        "",
        "",
        "    if len(shortlist) == 0:",
        "",
        "        print(\"[WARN] Shortlist vacía. Revisa umbrales/TopM o incrementa n_perm Stage-1.\")",
        "",
        "        return [], {\"res_stage1\": res1, \"shortlist\": [], \"res_stage2\": None, \"dedup\": None}",
        "",
        "",
        "",
        "    # Stage-2: MDA fino solo en shortlist",
        "",
        "    res2, per_fold2 = feature_mda_cv(",
        "",
        "        X_tr=X_tr, folds=folds, fold_models=fold_models,",
        "",
        "        features=shortlist,",
        "",
        "        n_perm=CFG[\"mda\"][\"stage2_n_perm\"],",
        "",
        "        random_state=rng_seed + 7,",
        "",
        "        verbose=verbose",
        "",
        "    )",
        "",
        "",
        "",
        "    # Ranking final antes de dedup",
        "",
        "    ranking = res2.sort_values([\"dAPF_median\",\"dAPF_q25\",\"hit_rate\"], ascending=False).reset_index(drop=True)",
        "",
        "    print(\"\\n=== Ranking (post Stage-2, pre-dedup) ===\")",
        "",
        "    display(ranking.head(20))",
        "",
        "",
        "",
        "    # Deduplicación por correlación (opcional)",
        "",
        "    whitelist_final = ranking[\"feature\"].tolist()",
        "",
        "    dedup_info = None",
        "",
        "    if CFG[\"dedup\"][\"do\"] and len(whitelist_final) > 1:",
        "",
        "        # Scores para greedy = dAPF_median (principal), fallback a q25",
        "",
        "        scores = {r[\"feature\"]: (float(r[\"dAPF_median\"]) + 1e-6*float(r[\"dAPF_q25\"])) for _, r in ranking.iterrows()}",
        "",
        "        wl_dedup = _greedy_dedup_by_corr(X_tr, whitelist_final, scores, corr_cap=CFG[\"dedup\"][\"corr_cap\"])",
        "",
        "        if verbose:",
        "",
        "            print(\"\\n=== Whitelist tras deduplicación por |ρ| ===\")",
        "",
        "            print(f\"Tamaño antes: {len(whitelist_final)} → después: {len(wl_dedup)}  (corr_cap={CFG['dedup']['corr_cap']})\")",
        "",
        "        whitelist_final = wl_dedup",
        "",
        "",
        "",
        "        # Dendrograma (opcional, visual)",
        "",
        "        if CFG[\"dedup\"][\"plot_dendrogram\"]:",
        "",
        "            try:",
        "",
        "                plot_feature_dendrogram(",
        "",
        "                    X_tr=X_tr, features=ranking[\"feature\"].tolist()[:min(200,len(ranking))],",
        "",
        "                    corr_method=CFG[\"dedup\"][\"corr_method\"],",
        "",
        "                    use_abs=CFG[\"dedup\"][\"use_abs\"],",
        "",
        "                    linkage_method=CFG[\"dedup\"][\"linkage\"],",
        "",
        "                    corr_cut=CFG[\"dedup\"][\"corr_cut_plot\"],",
        "",
        "                    max_leaves=CFG[\"dedup\"][\"max_leaves\"],",
        "",
        "                    title=\"HAC — shortlist (pre-dedup)\"",
        "",
        "                )",
        "",
        "            except Exception as e:",
        "",
        "                print(\"[WARN] No se pudo graficar dendrograma:\", e)",
        "",
        "",
        "",
        "        dedup_info = {\"corr_cap\": CFG[\"dedup\"][\"corr_cap\"], \"kept\": whitelist_final}",
        "",
        "",
        "",
        "    # Reporte",
        "",
        "    report = {",
        "",
        "        \"config\": CFG,",
        "",
        "        \"res_stage1\": res1,",
        "",
        "        \"shortlist\": shortlist,",
        "",
        "        \"res_stage2\": res2,",
        "",
        "        \"ranking_pre_dedup\": ranking,",
        "",
        "        \"dedup\": dedup_info,",
        "",
        "        \"whitelist_final\": whitelist_final",
        "",
        "    }",
        "",
        "",
        "",
        "    print(\"\\n=== WHITELIST FINAL (parsimoniosa) ===\")",
        "",
        "    print(whitelist_final)",
        "",
        "    print(f\"Tamaño final: {len(whitelist_final)}\")",
        "",
        "    return whitelist_final, report",
        "",
        ""
}
